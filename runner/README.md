# runner

Minimal agent runner that connects prompt, execution, and trace.

Design idea:
- load prompt from YAML (`prompt_lab`)
- execute via LLM API (mocked)
- log trace output to `trace_tools`

This is just scaffolding to see if a modular loop can emerge.
