llm:
  model: "gpt-4"
  temperature: 0.3

prompt_file: "../prompt_lab/basic_flow.yaml"
trace_output: "../trace_tools/"
